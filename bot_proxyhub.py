import os, json, datetime, asyncio
import requests
from bs4 import BeautifulSoup
from telegram import Bot
from telegram.constants import ParseMode

# ================= CONFIG =================
BOT_TOKEN = os.getenv("BOT_TOKEN")  # ØªÙˆÚ©Ù† Ø¨Ø§Øª
TARGET_CHAT = os.getenv("TARGET_CHAT")  # Ú©Ø§Ù†Ø§Ù„ Ù…Ù‚ØµØ¯
SOURCES = [
    "https://t.me/s/proxymtprotoir",
    "https://t.me/s/iMTProto",
    "https://t.me/s/TVProxy"
]
STATE_FILE = "last_proxy_messages.json"
MAX_LEN = 3800  # Ø­Ø¯Ø§Ú©Ø«Ø± Ø·ÙˆÙ„ Ù¾ÛŒØ§Ù…
# ==========================================

# Ù‡Ø¯Ø± Ù¾ÛŒØ§Ù…
HEADER = (
    "â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n"
    "ğŸ§© Ù¾Ø±ÙˆÚ©Ø³ÛŒ Ù‡Ø§Ø¨ | Proxy Hub\n"
    "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n\n"
)

# ÙÙˆØªØ± Ù¾ÛŒØ§Ù… Ø¨Ø¯ÙˆÙ† Ø§Ø·Ù„Ø§Ø¹Ø§Øª Ø§Ø¶Ø§ÙÛŒ
def footer(ts):
    return (
        "\n\nâ•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n"
        f"â± {ts}\n"
        "ğŸ“¡ @proxyhub_ir\n"
        "â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•"
    )

# Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ ÙˆØ¶Ø¹ÛŒØª Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§
def load_state():
    if os.path.exists(STATE_FILE):
        with open(STATE_FILE, "r", encoding="utf-8") as f:
            return json.load(f)
    return {}

# Ø°Ø®ÛŒØ±Ù‡ ÙˆØ¶Ø¹ÛŒØª Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§
def save_state(state):
    with open(STATE_FILE, "w", encoding="utf-8") as f:
        json.dump(state, f)

# Ø¯Ø±ÛŒØ§ÙØª Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ÛŒ Ú©Ø§Ù†Ø§Ù„ Ù…Ù†Ø¨Ø¹
def fetch_channel(url):
    r = requests.get(url, timeout=20)
    r.raise_for_status()
    soup = BeautifulSoup(r.text, "html.parser")

    messages = []
    for msg in soup.select("div.tgme_widget_message"):
        mid = msg.get("data-post")
        if not mid:
            continue

        text_div = msg.select_one("div.tgme_widget_message_text")
        if text_div:
            # ÙÙ‚Ø· Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ÛŒ <a> Ù¾Ø±ÙˆÚ©Ø³ÛŒ
            links = text_div.find_all("a", href=True)
            proxy_links = []
            for l in links:
                href = l['href'].strip()
                if any(proto in href.lower() for proto in ["vmess://", "vless://", "ss://", "trojan://", "hy2://", "http", "https"]):
                    proxy_links.append(f'<a href="{href}">{href}</a>')
            if proxy_links:
                messages.append((mid, proxy_links))
    return messages  # Ø¬Ø¯ÛŒØ¯ â†’ Ù‚Ø¯ÛŒÙ…

# Ø³Ø§Ø®Øª Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§ Ø¨Ø§ Ù‡Ø¯Ø± Ùˆ ÙÙˆØªØ± Ùˆ ØªÙ‚Ø³ÛŒÙ… Ø§Ù…Ù†
def build_messages(all_proxies):
    now = datetime.datetime.now().strftime("%Y-%m-%d %H:%M")
    messages = []
    cur = HEADER

    # Ù‡Ù…Ù‡ Ù„ÛŒÙ†Ú©â€ŒÙ‡Ø§ Ø¨Ø§ Ø§Ø³Ù¾ÛŒØ³ Ø¬Ø¯Ø§
    for proxies in all_proxies:
        line = " ".join(proxies) + " "
        if len(cur) + len(line) + len(footer(now)) > MAX_LEN:
            cur = cur.rstrip() + footer(now)
            messages.append(cur)
            cur = HEADER + line
        else:
            cur += line

    if cur.strip() != HEADER.strip():
        cur = cur.rstrip() + footer(now)
        messages.append(cur)

    return messages

# ØªØ§Ø¨Ø¹ Ø§ØµÙ„ÛŒ
async def main():
    bot = Bot(BOT_TOKEN)
    state = load_state()
    all_new_proxies = []

    for src in SOURCES:
        last = state.get(src)
        msgs = fetch_channel(src)

        for mid, proxies in msgs:
            if last and mid == last:
                break
            all_new_proxies.append(proxies)

        if msgs:
            state[src] = msgs[0][0]

    if not all_new_proxies:
        print("ğŸ“­ Ù‡ÛŒÚ† Ù¾ÛŒØ§Ù… Ø¬Ø¯ÛŒØ¯ÛŒ Ù†ÛŒØ³Øª")
        save_state(state)
        return

    messages = build_messages(all_new_proxies)

    for m in messages:
        await bot.send_message(
            chat_id=TARGET_CHAT,
            text=m,
            parse_mode=ParseMode.HTML,
            disable_web_page_preview=True
        )
        await asyncio.sleep(1)

    save_state(state)
    print(f"âœ… Ø§Ø±Ø³Ø§Ù„ Ø´Ø¯ | ØªØ¹Ø¯Ø§Ø¯ Ù¾ÛŒØ§Ù…â€ŒÙ‡Ø§: {len(all_new_proxies)}")

# Ø§Ø¬Ø±Ø§
if __name__ == "__main__":
    asyncio.run(main())
